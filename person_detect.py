import cv2
from ultralytics import YOLO


def person_detect(
    video_path: str,
    n_frames: int,
    model_path: str = "yolo11s.pt",  # ✅ веса YOLOv11 (Ultralytics)
    *,
    sample_every_n_frames: int = 3,    # ✅ ускорение: прогоняем через модель только каждый N-й кадр
    skip_first_n_frames: int = 2,      # ✅ сколько подряд "пустых" проверенных кадров разрешаем внутри серии
    imgsz: int = 416,                  # ✅ размер входа модели: меньше = быстрее, но хуже детект (обычно)
    conf: float = 0.35,                # ✅ порог уверенности: ниже = больше находок, но больше ложных
    iou: float = 0.5,                  # ✅ IoU для NMS: выше = сильнее объединяем близкие боксы
    max_seconds: float | None = None,  # ✅ ограничение анализа по времени (сек)
    device: str | int | None = None,   # ✅ "cpu", 0, "0" (GPU), None = авто
) -> bool:
    """
    Что делает:
    - Читает видео.
    - Запускает детекцию человека (COCO class=0) на выбранных кадрах.
    - Возвращает True, если удалось найти "серию" из n_frames проверенных кадров,
      где человек присутствует, и при этом допускаются "провалы" (кадры без человека)
      длиной до skip_first_n_frames подряд (внутри серии).

    Ключевой момент:
    - "подряд" считается ТОЛЬКО по кадрам, которые реально прогоняются через модель
      (то есть после фильтра sample_every_n_frames).
    """

    # ---------------------------------------------------------------------
    # 1) Валидация входных параметров (чтобы не словить тихие ошибки)
    # ---------------------------------------------------------------------
    if n_frames < 1:
        raise ValueError("n_frames должен быть >= 1")
    if sample_every_n_frames < 1:
        raise ValueError("sample_every_n_frames должен быть >= 1")
    if skip_first_n_frames < 0:
        raise ValueError("skip_first_n_frames должен быть >= 0")

    # ---------------------------------------------------------------------
    # 2) Загрузка модели YOLOv11
    #    Важно: сейчас модель загружается при каждом вызове функции.
    #    Если вы вызываете person_detect много раз, выгоднее:
    #    - загрузить модель один раз снаружи (model = YOLO(...))
    #    - и передавать её в функцию (или сделать отдельную функцию/класс)
    # ---------------------------------------------------------------------
    model = YOLO(model_path)

    # ---------------------------------------------------------------------
    # 3) Открываем видео
    # ---------------------------------------------------------------------
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"Не удалось открыть видео: {video_path}")

    # ---------------------------------------------------------------------
    # 4) Получаем FPS
    #    Это нужно, чтобы корректно посчитать ограничение max_seconds -> max_frames
    # ---------------------------------------------------------------------
    fps = cap.get(cv2.CAP_PROP_FPS)
    if not fps or fps <= 0:
        # Иногда FPS не читается (битый файл/поток/кодек).
        # Тогда берём дефолт, чтобы ограничение по времени всё равно работало.
        fps = 30.0

    # ---------------------------------------------------------------------
    # 5) Если задан лимит по времени, переведём его в лимит по кадрам
    #    frame_idx — индекс кадра в исходном видео (включая пропуски)
    # ---------------------------------------------------------------------
    max_frames = None
    if max_seconds is not None and max_seconds > 0:
        max_frames = int(round(max_seconds * fps))

    frame_idx = 0  # номер текущего кадра во всём видео (все кадры подряд)

    # ---------------------------------------------------------------------
    # 6) Переменные для логики "серии"
    #    run — сколько подряд (в смысле "проверенных") кадров с человеком уже набрали
    #    gap — сколько подряд (в смысле "проверенных") кадров без человека внутри текущей серии
    # ---------------------------------------------------------------------
    run = 0
    gap = 0

    # ---------------------------------------------------------------------
    # 7) Основной цикл чтения кадров
    # ---------------------------------------------------------------------
    try:
        while True:
            ok, frame = cap.read()

            # Если не удалось прочитать кадр — видео закончилось или ошибка чтения
            if not ok or frame is None:
                break

            # Ограничение по длительности анализа (в кадрах исходного видео)
            if max_frames is not None and frame_idx >= max_frames:
                break

            # -------------------------------------------------------------
            # 7.1) Пропуск кадров для ускорения:
            #      например sample_every_n_frames=3 -> берём кадры 0,3,6,9...
            # -------------------------------------------------------------
            if (frame_idx % sample_every_n_frames) != 0:
                frame_idx += 1
                continue

            # -------------------------------------------------------------
            # 7.2) Запускаем детекцию YOLOv11 на выбранном кадре
            #
            # classes=[0]    -> детектим только "person" (в COCO это класс 0)
            # conf/confidence -> отсечение слабых предсказаний
            # iou            -> параметр NMS (слияние/удаление дублей)
            # imgsz          -> размер входа сети (416 быстрее чем 640)
            # device         -> можно принудить CPU/GPU
            #
            # verbose=False  -> чтобы не засорять консоль логами
            # -------------------------------------------------------------
            results = model.predict(
                frame,
                classes=[0],
                conf=conf,
                iou=iou,
                imgsz=imgsz,
                device=device,
                verbose=False,
            )

            # -------------------------------------------------------------
            # 7.3) Извлекаем боксы (bbox)
            # results[0] — т.к. predict возвращает список результатов
            # boxes может быть пустым, если ничего не нашли
            # -------------------------------------------------------------
            boxes = results[0].boxes

            # Если хотя бы один бокс найден — считаем что "человек есть"
            person_now = boxes is not None and len(boxes) > 0

            # -------------------------------------------------------------
            # 7.4) Логика "серии" из n_frames:
            #
            # Если person_now=True:
            #   - увеличиваем run (серия растёт)
            #   - gap сбрасываем (провалов нет)
            #
            # Если person_now=False:
            #   - увеличиваем gap (дырка внутри серии)
            #   - если gap превысил допустимое значение -> серия сбрасывается
            # -------------------------------------------------------------
            if person_now:
                run += 1
                gap = 0
            else:
                gap += 1

                # Слишком длинная "дыра" — считаем серию прерванной
                if gap > skip_first_n_frames:
                    run = 0
                    gap = 0

            # -------------------------------------------------------------
            # 7.5) Условие успеха:
            #      как только набрали n_frames кадров с человеком (с учётом допусков),
            #      возвращаем True
            # -------------------------------------------------------------
            if run >= n_frames:
                return True

            # Увеличиваем индекс исходного кадра
            frame_idx += 1

        # Если дошли до конца видео/лимита — серия так и не набралась
        return False

    finally:
        # Даже если случится исключение — VideoCapture корректно закроется
        cap.release()
